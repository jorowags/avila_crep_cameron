theme(
axis.text.x = element_text(angle = 0, vjust = 0.5, hjust=1),
plot.title = element_text(hjust = 0.5)
) +
labs(x = "Year", y = "Mean Total Score", title = "Mean Total Scores by Year with 95% CI")
# Print the plot to display in the R Markdown document
p
# Save the plot as a jpg file
ggsave("fig3.jpg", plot = p, device = "jpg", width = 12, height = 8, units = "in", bg = "white")
phi(usa.dishwasher.table)
phi(usa.car.table)
phi(usa.soap.table)
knitr::opts_chunk$set(echo = TRUE)
# Define a function to format the p-values
format_p <- function(p_value) {
if (p_value < .001) {
return("*p* < .001")
} else {
return(paste0("*p* = ", round(p_value, 3)))
}
}
packages = c("psych","dplyr","tidyverse", "lme4")
## Now load or install&load all
package.check <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
url <- "https://raw.githubusercontent.com/jorowags/avila_crep_cameron/main/avila_cameron_data.csv"
initial_data <- read.csv(url)
data <- initial_data
# rename variables
names(data)[names(data) == "Q004_03"] <- "age"
## XXX rename other variables
# remove participants who did not finish study
data <- subset(data, data$LASTPAGE > 85)
# remove minors
data <- subset(data, data$age > 17)
# remove participants who didn't complete the tasks
# Create a logical matrix where each cell is TRUE if the corresponding value is -1
incomplete_tasks = data[, paste0("C", sprintf("%03d", 1:40))] < 0
# Sum these logical values row-wise. Any row with a sum greater than 0 has at least one -1 value
rows_to_exclude = rowSums(incomplete_tasks) > 0
# Exclude these rows from the dataset
data <- data[!rows_to_exclude, ]
# remove cases with "test" in gender
data <- subset(data, !grepl("Test", age, ignore.case = TRUE))
# Initialize new variables
for (i in 1:40) {
new_var <- paste0("T", sprintf("%03d", i))
data[[new_var]] <- NA
}
# Populate the new variables with the choices
for (row in 1:nrow(data)) {
for (i in 1:40) {
# Get the trial column name and stimulus number
trial_col <- paste0("R001x", sprintf("%02d", i))
stimulus_num <- data[row, trial_col]
# Get the choice column name
choice_col <- paste0("C", sprintf("%03d", stimulus_num))
# Get the new variable name
new_var <- paste0("T", sprintf("%03d", i))
# Populate the new variable with the choice
data[row, new_var] <- data[row, choice_col]
}
}
knitr::opts_chunk$set(echo = TRUE)
# Define a function to format the p-values
format_p <- function(p_value) {
if (p_value < .001) {
return("*p* < .001")
} else {
return(paste0("*p* = ", round(p_value, 3)))
}
}
packages = c("psych","dplyr","tidyverse", "lme4")
## Now load or install&load all
package.check <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
url <- "https://raw.githubusercontent.com/jorowags/avila_crep_cameron/main/avila_cameron_data.csv"
initial_data <- read.csv(url)
data <- initial_data
# rename variables
names(data)[names(data) == "Q004_03"] <- "age"
## XXX rename other variables
# remove participants who did not finish study
data <- subset(data, data$LASTPAGE > 85)
# remove minors
data <- subset(data, data$age > 17)
# remove participants who didn't complete the tasks
# Create a logical matrix where each cell is TRUE if the corresponding value is -1
incomplete_tasks = data[, paste0("C", sprintf("%03d", 1:40))] < 0
# Sum these logical values row-wise. Any row with a sum greater than 0 has at least one -1 value
rows_to_exclude = rowSums(incomplete_tasks) > 0
# Exclude these rows from the dataset
data <- data[!rows_to_exclude, ]
# remove cases with "test" in gender
data <- subset(data, !grepl("Test", age, ignore.case = TRUE))
# Initialize new variables
for (i in 1:40) {
new_var <- paste0("T", sprintf("%03d", i))
data[[new_var]] <- NA
}
# Populate the new variables with the choices
for (row in 1:nrow(data)) {
for (i in 1:40) {
# Get the trial column name and stimulus number
trial_col <- paste0("R001x", sprintf("%02d", i))
stimulus_num <- data[row, trial_col]
# Get the choice column name
choice_col <- paste0("C", sprintf("%03d", stimulus_num))
# Get the new variable name
new_var <- paste0("T", sprintf("%03d", i))
# Populate the new variable with the choice
data[row, new_var] <- data[row, choice_col]
}
}
# N
## Calculate number of cases in initial data
n_initial <- length(unique(initial_data$CASE[initial_data$CASE != "NANA"]))
n_final <- length(unique(data$CASE[data$CASE != "NANA"]))
n_exclusions <- as.numeric(n_initial) - as.numeric(n_final)
## Calculate number of cases in final data
# Age M and SD
## Clean up age variable
data$age <- gsub("\\D", "", data$age)
age_m <- sprintf("%.2f", mean(as.numeric(data$age)), 2)
age_sd <- sprintf("%.2f", sd(as.numeric(data$age)), 2)
# gender
## Clean up variable
names(data)[names(data) == "Q004_01"] <- "gender"
data$gender <- gsub("alpha male","male", data$gender)
data$gender <- gsub("I am a damn male","male", data$gender)
data$gender <- gsub("MALE","male", data$gender)
data$gender <- gsub("Male","male", data$gender)
data$gender <- gsub("Straight male","male", data$gender)
data$gender <- gsub("male ","male", data$gender)
data$gender <- gsub("Female","female", data$gender)
## Get gender percentages
female_percentage <- sprintf("%.2f", prop.table(table(data$gender))["female"] * 100, 2)
male_percentage <- sprintf("%.2f", prop.table(table(data$gender))["male"] * 100, 2)
nb_percentage <- sprintf("%.2f", prop.table(table(data$gender))["non-binary"] * 100, 2)
# Race/ethnicity
## Clean up variable
names(data)[names(data) == "Q004_02"] <- "race"
data$race <- gsub("AA/Caucasian","Multiracial", data$race)
data$race <- gsub("Hispanic/latino","Hispanic", data$race)
data$race <- gsub("White/Caucasian ","White", data$race)
data$race <- gsub("White/Hispanic","Multiracial", data$race)
data$race <- gsub("African American ", "Black", data$race)
data$race <- gsub("Black American ", "Black", data$race)
data$race <- gsub("African American", "Black", data$race)
data$race <- gsub("Caucasian ", "White", data$race)
data$race <- gsub("white ", "White", data$race)
data$race <- gsub("caucasian", "White", data$race)
data$race <- gsub("Caucasian", "White", data$race)
data$race <- gsub("white", "White", data$race)
data$race <- gsub("hispanic", "Hispanic", data$race)
data$race <- gsub("Indian ", "Indian", data$race)
data$race <- gsub("Native Indian", "Indigenous", data$race)
data$race <- gsub("None ", "None Reported", data$race)
## Get race percentages
white_percentage <- sprintf("%.2f", prop.table(table(data$race))["White"] * 100, 2)
black_percentage <- sprintf("%.2f", prop.table(table(data$race))["Black"] * 100, 2)
hispanic_percentage <- sprintf("%.2f", prop.table(table(data$race))["Hispanic"] * 100, 2)
indian_percentage <- sprintf("%.2f", prop.table(table(data$race))["Indian"] * 100, 2)
indigenous_percentage <- sprintf("%.2f", prop.table(table(data$race))["Indigenous"] * 100, 2)
multiracial_percentage <- sprintf("%.2f", prop.table(table(data$race))["Multiracial"] * 100, 2)
none_percentage <- sprintf("%.2f", prop.table(table(data$race))["None Reported"] * 100, 2)
# take mean of deck choices – numbers closer to 2 indicate more “Feel”, closer to 1 indicate more “Describe”, subtract 1 to get numbers similar to theirs
# Calculate and store the choice_index
data$choice_index <- rowMeans(data[, paste0("C", sprintf("%03d", 1:40))]) - 1
# Calculate the overall mean of choice_index for all participants
mean_choice_index <- mean(data$choice_index, na.rm = TRUE)
#calculate NASA
## RedNASA - describe (objective) deck
### Rename variables
names(data)[names(data) == "Q002_01"] <- "RedNASA_demanding"
names(data)[names(data) == "Q002_02"] <- "RedNASA_hard_work"
names(data)[names(data) == "Q002_03"] <- "RedNASA_aversion"
names(data)[names(data) == "Q002_04"] <- "RedNASA_efficacy"
### Replace -9 with "NA"
data$RedNASA_demanding[data$RedNASA_demanding == "-9"] <- NA
data$RedNASA_hard_work[data$RedNASA_hard_work == "-9"] <- NA
data$RedNASA_aversion[data$RedNASA_aversion == "-9"] <- NA
data$RedNASA_efficacy[data$RedNASA_efficacy == "-9"] <- NA
### Add variables for "subscales"
data$RedNASA_effort <- (data$RedNASA_demanding+data$RedNASA_hard_work)/2
## BlueNASA - feel (empathy) deck
### Rename variables
names(data)[names(data) == "Q003_01"] <- "BlueNASA_demanding"
names(data)[names(data) == "Q003_02"] <- "BlueNASA_hard_work"
names(data)[names(data) == "Q003_03"] <- "BlueNASA_aversion"
names(data)[names(data) == "Q003_04"] <- "BlueNASA_efficacy"
### Replace -9 with "NA"
data$BlueNASA_demanding[data$BlueNASA_demanding == "-9"] <- NA
data$BlueNASA_hard_work[data$BlueNASA_hard_work == "-9"] <- NA
data$BlueNASA_aversion[data$BlueNASA_aversion == "-9"] <- NA
data$BlueNASA_efficacy[data$BlueNASA_efficacy == "-9"] <- NA
### Add variables for "subscales"
data$BlueNASA_effort <- (data$BlueNASA_demanding+data$BlueNASA_hard_work)/2
# calculate MFI. Higher scores = more fatigue
# Rename variables
# Create vector of old and new names
old_names <- paste0("EX01_", sprintf("%02d", 1:20))
new_names <- paste0("MFI_", sprintf("%02d", 1:20))
# Rename the columns
names(data)[names(data) %in% old_names] <- new_names
## Replace -9 with "NA" on all variables
data <- data %>%
mutate_at(vars(paste0("MFI_", sprintf("%02d", 1:20))),
~replace(., . == -9, NA))
#3.	Same as #2, but for Aversive
#4.	Same as #3, but for Efficacy
#5.	Correlation: deck selection and effodiff
#6.	Correlation: deck selection and affdiff
#7.	Correlation: deck selection and NASA effidiff
# Time course analysis -- see https://osf.io/w8czf
#	One-sample t-test against .5 for deck selection
deck_t_result <- t.test(data$choice_index, mu = 0.5)
# Extract the necessary values for reporting
one_t_value <- round(deck_t_result$statistic, 2)
one_df <- round(deck_t_result$parameter, 0)
one_p_value <- round(deck_t_result$p.value, 3)
one_mean <- round(deck_t_result$estimate, 2)
one_ci_low <- round(deck_t_result$conf.int[1], 2)
one_ci_high <- round(deck_t_result$conf.int[2], 2)
#	One-sample t-test: EffortDiff (empathy minus objective) deck selection -> NASA effort, test against 0
## Create effortdiff score by calculating objective NASA - empathy NASA. Values below 0 indicate that empathy was more effortful.
data$effortdiff <- data$RedNASA_effort - data$BlueNASA_effort
# Conduct one-sample t-test
effort_t_result <- t.test(data$effortdiff, mu = 0)
# Extract the necessary values for reporting
effortdiff_t_value <- round(effort_t_result$statistic, 2)
effortdiff_df <- round(effort_t_result$parameter, 0)
effortdiff_p_value <- round(effort_t_result$p.value, 3)
effortdiff_mean <- round(effort_t_result$estimate, 2)
effortdiff_ci_low <- round(effort_t_result$conf.int[1], 2)
effortdiff_ci_high <- round(effort_t_result$conf.int[2], 2)
### Effect size
# Calculate Cohen's d
effortdiff_cohens_d <- round(mean(data$effortdiff) / sd(data$effortdiff), 2)
#	One-sample t-test: aversiveness (empathy minus objective) -> NASA aversion, test against 0
## Create aversion score by calculating aversiveness scores for red minus blue decks. Values below 0 indicate that empathy was more aversive
data$aversion <- data$RedNASA_aversion - data$BlueNASA_aversion
# Conduct one-sample t-test
aversion_t_result <- t.test(data$aversion, mu = 0)
# Extract the necessary values for reporting
aversion_t_value <- round(aversion_t_result$statistic, 2)
aversion_df <- round(aversion_t_result$parameter, 0)
aversion_p_value <- round(aversion_t_result$p.value, 3)
aversion_mean <- round(aversion_t_result$estimate, 2)
aversion_ci_low <- round(aversion_t_result$conf.int[1], 2)
aversion_ci_high <- round(aversion_t_result$conf.int[2], 2)
### Effect size
# Calculate Cohen's d
aversion_cohens_d <- round(mean(data$aversion) / sd(data$aversion), 2)
#	One-sample t-test: efficacy (empathy minus objective) -> NASA efficacy, test against 0
## Create efficacy score by calculating red minus blue decks. Values above 0 indicate that the red deck (describe) was more efficacious
data$efficacy <- data$RedNASA_efficacy - data$BlueNASA_efficacy
# Conduct one-sample t-test
efficacy_t_result <- t.test(data$efficacy, mu = 0)
# Extract the necessary values for reporting
efficacy_t_value <- round(efficacy_t_result$statistic, 2)
efficacy_df <- round(efficacy_t_result$parameter, 0)
efficacy_p_value <- round(efficacy_t_result$p.value, 3)
efficacy_mean <- round(efficacy_t_result$estimate, 2)
efficacy_ci_low <- round(efficacy_t_result$conf.int[1], 2)
efficacy_ci_high <- round(efficacy_t_result$conf.int[2], 2)
### Effect size
# Calculate Cohen's d
efficacy_cohens_d <- round(mean(data$efficacy) / sd(data$efficacy), 2)
choice_effort <- corr.test(data$choice_index, data$effortdiff)
print(choice_effort, short = FALSE)
choice_effort_r_value <- round(choice_effort$r, 2)
choice_effort_df <- choice_effort$n - 2
choice_effort_p_value <- round(choice_effort$p, 3)
choice_effort_ci_lower <- round(choice_effort$ci$lower, 2)
choice_effort_ci_upper <- round(choice_effort$ci$upper, 2)
choice_aversion <- corr.test(data$choice_index, data$aversion)
print(choice_aversion, short = FALSE)
choice_aversion_r_value <- round(choice_aversion$r, 2)
choice_aversion_df <- choice_aversion$n - 2
choice_aversion_p_value <- round(choice_aversion$p, 3)
choice_aversion_ci_lower <- round(choice_aversion$ci$lower, 2)
choice_aversion_ci_upper <- round(choice_aversion$ci$upper, 2)
choice_efficacy <- corr.test(data$choice_index, data$efficacy)
print(choice_efficacy, short = FALSE)
#scatterplot
library(ggplot2)
# Basic scatter plot
scatterplot <- ggplot(data, aes(x=efficacy, y=choice_index)) +
geom_point(size=1.5, shape=19) +
geom_point()+
geom_smooth(method=lm, se=FALSE, color="black")+
labs(title="Deck choice frequency by perceived efficacy",
x="Efficacy (perceived efficacy of objective deck)", y = "Choice Index (rate of choosing empathy deck)")
ggsave("scatterplot.png", plot = scatterplot, width = 6, height = 4, dpi = 300)
choice_efficacy_r_value <- round(choice_efficacy$r, 2)
choice_efficacy_df <- choice_efficacy$n - 2
choice_efficacy_p_value <- round(choice_efficacy$p, 8)
choice_efficacy_ci_lower <- round(choice_efficacy$ci$lower, 2)
choice_efficacy_ci_upper <- round(choice_efficacy$ci$upper, 2)
# Center means for effortdiff, aversion, efficacy, choice
# Subtract the mean from each observation to center the variable
data$effortdiff_centered <- data$effortdiff - effortdiff_mean
data$efficacy_centered <- data$efficacy - mean(data$efficacy)
data$aversion_centered <- data$aversion - aversion_mean
# Create a tall subset with time course choices
tall_data <- data %>%
pivot_longer(
cols = c("T001", "T002", "T003", "T004", "T005", "T006", "T007", "T008", "T009", "T010",
"T011", "T012", "T013", "T014", "T015", "T016", "T017", "T018", "T019", "T020",
"T021", "T022", "T023", "T024", "T025", "T026", "T027", "T028", "T029", "T030",
"T031", "T032", "T033", "T034", "T035", "T036", "T037", "T038", "T039", "T040"),
names_to = "Trial",
values_to = "Value"
)
new_values <- setNames(as.character(1:40), paste0("T", sprintf("%03d", 1:40)))
# Recode values in the column
tall_data$Trial <- as.numeric(recode(tall_data$Trial, !!! new_values))
# Examine interactions between effortdiff, aversion, efficacy, and time course
# Generalized linear mixed model examining choice (empathy =1) over time
# Includes random intercept and random slope for time, autoregressive covariance parameter
# Time centered to start at 0 (0 - 39)
tall_data$Trial_centered <- tall_data$Trial - 1
# Value set to 0 and 1
tall_data$Value_centered <- tall_data$Value - 1
model1 <- glmer(Value_centered ~ Trial_centered + (Trial_centered | CASE), data = tall_data, family = binomial(link = "logit"))
# Examining interaction of Time x mean-centered NASA effort ratings (empathy deck - objective deck)
model2 <- glmer(Value_centered ~ Trial_centered * effortdiff_centered + (Trial_centered | CASE), data = tall_data, family = binomial(link = "logit"))
# Examining interaction of Time x mean-centered NASA efficacy ratings
model3 <- glmer(Value_centered ~ Trial_centered * efficacy_centered + (Trial_centered | CASE),
data = tall_data,
family = binomial(link = "logit"),
control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e5)))
# Examining interaction of Time x mean-centered NASA aversion ratings
model4 <- glmer(Value_centered ~ Trial_centered * aversion_centered + (Trial_centered | CASE), data = tall_data, family = binomial(link = "logit"))
# Print summary of models
summary(model1)
beta_Trial_centered <- fixef(model1)["Trial_centered"]
pr_value_Trial_centered <- round(summary(model1)$coefficients["Trial_centered", "Pr(>|z|)"], 2)
summary(model2)
beta_interaction_effortdiff <- fixef(model2)["Trial_centered:effortdiff_centered"]
pr_value_interaction_effortdiff <- round(summary(model2)$coefficients["Trial_centered:effortdiff_centered", "Pr(>|z|)"], 2)
summary(model3)
beta_interaction_efficacy <- fixef(model3)["Trial_centered:efficacy_centered"]
pr_value_interaction_efficacy <- round(summary(model3)$coefficients["Trial_centered:efficacy_centered", "Pr(>|z|)"], 2)
pr_value_interaction_efficacy <- ifelse(pr_value_interaction_efficacy == 0, "< .001", pr_value_interaction_efficacy)
summary(model4)
beta_interaction_aversion <- fixef(model4)["Trial_centered:aversion_centered"]
pr_value_interaction_aversion <- round(summary(model4)$coefficients["Trial_centered:aversion_centered", "Pr(>|z|)"], 2)
# Visualization of aggregated choices across participants over time
time_plot <- ggplot(tall_data, aes(x = Trial_centered, fill = as.factor(Value_centered))) +
geom_bar(position = "fill") +
labs(title = "Choices Over Time",
x = "Trial Centered", y = "Proportion", fill = "Deck Choice") +
scale_fill_manual(values = c("red", "blue"), labels = c("Objective (Describe)", "Empathy (Feel)")) +
theme_minimal()
ggsave("time_plot.png", plot = time_plot, width = 6, height = 4, dpi = 300)
show(time_plot)
# Choices over time by participant
# Obtain the predicted probabilities from the model
tall_data$Predicted <- predict(model1, type = "response")
# Create a plot of the predicted probabilities
participant_time <- ggplot(tall_data, aes(x = Trial_centered, y = Predicted, group = CASE, color = as.factor(CASE))) +
geom_line() +
labs(title = "Changes in Response Over Time by CASE",
x = "Trial Centered", y = "Predicted Probability") +
theme_minimal() +
guides(color = FALSE)
ggsave("participant_time.png", plot = participant_time, width = 6, height = 4, dpi = 300)
show(participant_time)
#efficacy/time interaction
# Convert efficacy_centered to a factor with 3 levels
tall_data$efficacy_levels <- cut(tall_data$efficacy_centered, breaks = 2, labels = c("Empathy", "Objective"))
# Create an interaction plot with 3 levels of efficacy
interaction_efficacy <- interaction.plot(tall_data$Trial_centered, tall_data$efficacy_levels, tall_data$Predicted,
xlab = "Trial (0 to 39)", ylab = "Choice (high = more empathy)",
trace.label = "Deck with\n more efficacy", legend = TRUE)
dev.print(png, file = "interaction_plot.png", width = 6, height = 4, units = "in", res = 300)
## Reverse code 01, 03, 04, 06, 07, 08, 11, 12, 15, 20
data$MFI_01_R <- 8 - data$MFI_01
data$MFI_03_R <- 8 - data$MFI_03
data$MFI_04_R <- 8 - data$MFI_04
data$MFI_06_R <- 8 - data$MFI_06
data$MFI_07_R <- 8 - data$MFI_07
data$MFI_08_R <- 8 - data$MFI_08
data$MFI_11_R <- 8 - data$MFI_11
data$MFI_12_R <- 8 - data$MFI_12
data$MFI_15_R <- 8 - data$MFI_15
data$MFI_20_R <- 8 - data$MFI_20
## Calculate Subscales
### generalfatigue (items 1R, 5, 12R, 16)
data$MFI_general = data$MFI_01_R + data$MFI_05 + data$MFI_12_R + data$MFI_16
#### general fatigue alpha
general_subscale <- data[, c("MFI_01_R", "MFI_05", "MFI_12_R", "MFI_16")]
##### Compute Cronbach's alpha
psych::alpha(general_subscale)
### mental fatigue (items 7R, 11R, 13, 19)
data$MFI_mental = data$MFI_07_R + data$MFI_11_R + data$MFI_13 + data$MFI_19
#### mental fatigue alpha
mental_subscale <- data[, c("MFI_07_R", "MFI_11_R", "MFI_13", "MFI_19")]
##### Compute Cronbach's alpha
psych::alpha(mental_subscale)
### physical fatigue (items 2, 8R, 14, 20R)
data$MFI_physical = data$MFI_02 + data$MFI_08_R + data$MFI_14 + data$MFI_20_R
#### general fatigue alpha
physical_subscale <- data[, c("MFI_02", "MFI_08_R", "MFI_14", "MFI_20_R")]
##### Compute Cronbach's alpha
psych::alpha(physical_subscale)
### reduced motivation (items 4R, 9, 15R, 18)
data$MFI_motivation = data$MFI_04_R + data$MFI_09 + data$MFI_15_R + data$MFI_18
#### general fatigue alpha
motivation_subscale <- data[, c("MFI_04_R", "MFI_09", "MFI_15_R", "MFI_18")]
##### Compute Cronbach's alpha
psych::alpha(motivation_subscale)
### reduced activity (items 3R, 6R, 10, 17)
data$MFI_activity = data$MFI_03_R + data$MFI_06_R + data$MFI_10 + data$MFI_17
#### general fatigue alpha
activity_subscale <- data[, c("MFI_03_R", "MFI_06_R", "MFI_10", "MFI_17")]
##### Compute Cronbach's alpha
psych::alpha(activity_subscale)
# Correlate these with choice variables
# Define the list of variables
variables <- c("choice_index", "effortdiff", "aversion", "efficacy", "MFI_general", "MFI_mental", "MFI_physical", "MFI_motivation", "MFI_activity")
# Subset the dataframe to include only the desired variables
data_subset <- data[, variables]
# Calculate the correlation matrix
correlation_matrix <- cor(data_subset, use = "pairwise.complete.obs")
# Print the correlation matrix
print(correlation_matrix)
# Compute correlation matrix with p-values
cor_results <- corr.test(data_subset)
# Extract the correlation matrix
cor_matrix <- cor_results$r
# Extract the p-value matrix
p_matrix <- cor_results$p
# Find significant correlations (e.g., at the 0.05 level)
sig_indices <- which(p_matrix < 0.05, arr.ind = TRUE)
# Data frame to store the results
results <- data.frame(
variable1 = character(),
variable2 = character(),
correlation = numeric(),
p_value = numeric(),
stringsAsFactors = FALSE
)
# pull out the mental fatigue r and p
mf_choice_r <- formatC(round(cor_matrix[6, 1], 2), format = "f", digits = 2, decimal.mark = ".")
mf_choice_r <- sub("^0", "", mf_choice_r)
mf_choice_p <- formatC(round(p_matrix[6, 1], 2), format = "f", digits = 2, decimal.mark = ".")
mf_choice_p <- sub("^0", "", mf_choice_p)
# pull out the physical fatigue r and p -- this is a NEGATIVE CORRELATION for our data -- if this changes, re-write the sub/paste lines!!
pf_choice_r <- formatC(round(cor_matrix[7, 1], 2), format = "f", digits = 2, decimal.mark = ".")
pf_choice_r <- sub("^-0", "", pf_choice_r)
pf_choice_r <- paste0("-", pf_choice_r)
pf_choice_p <- formatC(round(p_matrix[7, 1], 2), format = "f", digits = 2, decimal.mark = ".")
pf_choice_p <- sub("^0", "", pf_choice_p)
# pull out the significant motivation - choice correlation
mot_choice_r <- formatC(round(cor_matrix[8, 1], 2), format = "f", digits = 2, decimal.mark = ".")
mot_choice_r <- sub("^0", "", mot_choice_r)
mot_choice_p <- formatC(round(cor_matrix[8, 1], 2), format = "f", digits = 2, decimal.mark = ".")
mot_choice_p <- sub("^0", "", mot_choice_p)
mot_choice_test <- cor.test(data$MFI_motivation, data$choice_index)
mot_choice_t <- round(mot_choice_test$statistic, 2)
mot_choice_df <- mot_choice_test$parameter
print(results)
packages = c("psych","dplyr","tidyverse", "lme4", "trackdown")
## Now load or install&load all
package.check <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
trackdown::upload_file(file = "https://drive.google.com/drive/folders/1bBky9pCcxt1VVPMjRWs_zPQc44x01jd4?usp=drive_link/cameron_trackdown.Rmd", hide_code = TRUE)
trackdown::upload_file(file = "https://docs.google.com/document/d/1kwokYAjQdZHiUzllAxwnLRBt0oc0II08lHp7xLqDKts/edit?usp=sharing", hide_code = TRUE)
trackdown::upload_file(file = "https://drive.google.com/drive/folders/1bBky9pCcxt1VVPMjRWs_zPQc44x01jd4?usp=sharing/avila_crep_cameron.Rmd", hide_code = TRUE)
trackdown::upload_file(file = "https://drive.google.com/drive/folders/1bBky9pCcxt1VVPMjRWs_zPQc44x01jd4?usp=sharing/avila_crep_cameron.Rmd", hide_code = TRUE)
trackdown::upload_file(file = "https://github.com/jorowags/avila_crep_cameron/blob/b60c93a16e188e3e867b9f5584f99abc3843b00f/avila_crep_cameron.Rmd", hide_code = TRUE)
trackdown::upload_file(file = "Documents\Github\avila_crep_cameron\avila_crep_cameron.Rmd", hide_code = TRUE)
trackdown::upload_file(file = "Users\jordanwagge\Documents\GitHub\avila_crep_cameron\avila_crep_cameron.Rmd", hide_code = TRUE)
trackdown::upload_file(file = "Users/jordanwagge/Documents/GitHub/avila_crep_cameron/avila_crep_cameron.Rmd", hide_code = TRUE)
trackdown::upload_file(file = "avila_crep_cameron/avila_crep_cameron.Rmd", hide_code = TRUE)
trackdown::upload_file(file = "/avila_crep_cameron/avila_crep_cameron.Rmd", hide_code = TRUE)
setwd("~/Documents/GitHub/avila_crep_cameron")
trackdown::upload_file(file = "/avila_crep_cameron/avila_crep_cameron.Rmd", hide_code = TRUE)
trackdown::upload_file(file = "Users/jordanwagge/Documents/GitHub/avila_crep_cameron/avila_crep_cameron.Rmd", hide_code = TRUE)
trackdown::upload_file((file = "avila_crep_cameron.Rmd"))
trackdown::upload_file((file = "avila_crep_cameron.Rmd"))
rlang::last_error
library(googledrive)
trackdown::upload_file((file = "avila_crep_cameron.Rmd"))
dir
head(df)
head(data)
colnames(data)
